# AI/ML System Architecture - Backend

This document explains how the AI/ML forecasting system works in the backend, including automatic learning, model training, and prediction workflows.

---

## Table of Contents

- [System Overview](#system-overview)
- [Core Components](#core-components)
- [AI Workflow](#ai-workflow)
- [Automatic Learning System](#automatic-learning-system)
- [Model Training Process](#model-training-process)
- [Available AI Models](#available-ai-models)
- [Data Flow](#data-flow)
- [API Integration](#api-integration)
- [Configuration](#configuration)

---

## System Overview

The backend implements a **fully automated AI/ML forecasting system** that:

1. **Automatically trains** models when new data is added
2. **Supports 6 different ML algorithms** for forecasting
3. **Compares multiple models** and selects the best performer
4. **Provides predictions** for revenue, expenses, and inventory
5. **Runs on a schedule** for periodic retraining

### Key Features

- ✅ **Auto-learning**: Models retrain automatically when sufficient new data is available
- ✅ **Multi-model approach**: Trains multiple algorithms and picks the best one
- ✅ **Background processing**: Training happens asynchronously without blocking API requests
- ✅ **Persistent storage**: Trained models are saved and reused for predictions
- ✅ **Advanced metrics**: Tracks MAE, RMSE, R², AIC, and more
- ✅ **Scheduled retraining**: Automatic weekly/daily model updates

---

## Core Components

### 1. ML Forecasting Service (`ml_forecasting.py`)

**Purpose**: Core AI model training and prediction engine

**Location**: `app/services/ml_forecasting.py`

**Responsibilities**:
- Implements all 6 ML algorithms (ARIMA, SARIMA, Prophet, XGBoost, LSTM, Linear Regression)
- Prepares time-series data from database
- Trains models and calculates performance metrics
- Saves/loads trained models to/from disk
- Generates forecasts for future periods

**Key Methods**:
```python
# Training methods for each model type
train_arima_expenses(db, start_date, end_date)
train_prophet_revenue(db, start_date, end_date)
train_lstm_revenue(db, start_date, end_date)
train_sarima_inventory(db, start_date, end_date)
train_xgboost_revenue(db, start_date, end_date)
train_linear_regression_expenses(db, start_date, end_date)

# Prediction methods
forecast_expenses(db, model_type, periods)
forecast_revenue(db, model_type, periods)
forecast_inventory(db, model_type, periods)
```

---

### 2. Auto-Learning Service (`ml_auto_learn.py`)

**Purpose**: Intelligent automatic model retraining system

**Location**: `app/services/ml_auto_learn.py`

**Responsibilities**:
- Monitors when new data is added (revenue, expenses, inventory)
- Decides when to retrain models based on data volume
- Trains multiple model types and compares performance
- Automatically replaces old models with better-performing ones
- Tracks training history and statistics

**How It Works**:

```python
# 1. When user adds new data (e.g., expense)
record_new_data("expense", count=1)

# 2. Check if retraining is needed
if should_retrain("expense"):
    # 3. Trigger auto-learning in background
    trigger_auto_learn_background("expense")
```

**Auto-Learning Logic**:
- Tracks new data count since last training
- Requires minimum threshold before retraining (e.g., 5 new entries)
- Enforces cooldown period (e.g., 24 hours) between retraining
- Trains multiple models (Linear Regression, ARIMA, Prophet, XGBoost, LSTM)
- Compares MAE/RMSE and keeps the best model

---

### 3. ML Scheduler (`ml_scheduler.py`)

**Purpose**: Scheduled automatic model retraining

**Location**: `app/services/ml_scheduler.py`

**Responsibilities**:
- Schedules periodic model retraining (weekly, daily, etc.)
- Uses APScheduler for background job management
- Can retrain all models or specific metrics
- Integrates with auto-learning service

**Configuration**:
```python
# Environment variables
ML_SCHEDULER_ENABLED=true
ML_SCHEDULER_DAY=mon        # Monday
ML_SCHEDULER_HOUR=2         # 2 AM
ML_SCHEDULER_MINUTE=0
```

**Usage**:
```python
# Start scheduler (runs every Monday at 2 AM)
start_scheduler(use_auto_learn=True)

# Schedule specific metric retraining
schedule_metric_retraining("revenue", hour=3, day_of_week="daily")
```

---

### 4. Advanced Training Module (`ml_advanced_training.py`)

**Purpose**: Advanced ML features and optimizations

**Location**: `app/services/ml_advanced_training.py`

**Features**:
- **Hyperparameter optimization**: Automatically finds best model parameters
- **Cross-validation**: Time-series cross-validation for robust evaluation
- **Outlier detection**: Removes anomalies from training data
- **Advanced metrics**: Calculates MAPE, R², AIC, BIC, etc.
- **Model versioning**: Tracks model versions and metadata
- **Training monitoring**: Callbacks for tracking training progress

---

## AI Workflow

### Complete End-to-End Flow

```
┌─────────────────────────────────────────────────────────────────┐
│                    USER ADDS NEW DATA                           │
│              (Revenue, Expense, Inventory, Sale)                │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│                  API ENDPOINT (FastAPI)                         │
│         POST /api/v1/revenue/                                   │
│         POST /api/v1/expenses/                                  │
│         POST /api/v1/inventory/                                 │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│              RECORD NEW DATA (ml_auto_learn)                    │
│         record_new_data("revenue", count=1)                     │
│         Increments counter for this metric                      │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│         TRIGGER AUTO-LEARN (Background Task)                    │
│         background_tasks.add_task(                              │
│             trigger_auto_learn_background, "revenue"            │
│         )                                                       │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│              CHECK IF RETRAINING NEEDED                         │
│         - Enough new data? (>= 5 entries)                       │
│         - Cooldown period passed? (>= 24 hours)                 │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼ YES
┌─────────────────────────────────────────────────────────────────┐
│           TRAIN MULTIPLE MODELS (Parallel)                      │
│         ┌──────────────────────────────────────┐                │
│         │ 1. Linear Regression (baseline)      │                │
│         │ 2. ARIMA (time series)               │                │
│         │ 3. Prophet (seasonal patterns)       │                │
│         │ 4. XGBoost (gradient boosting)       │                │
│         │ 5. LSTM (deep learning)              │                │
│         └──────────────────────────────────────┘                │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│              EVALUATE & COMPARE MODELS                          │
│         - Calculate MAE, RMSE for each model                    │
│         - Rank by performance (lower MAE = better)              │
│         - Select best performing model                          │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│              SAVE BEST MODEL TO DISK                            │
│         Path: backend/model/{metric}_{model_type}.pkl           │
│         Metadata: backend/store/{metric}_{model_type}.json      │
└────────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
┌─────────────────────────────────────────────────────────────────┐
│              MODEL READY FOR PREDICTIONS                        │
│         GET /api/v1/budgeting/forecast/{metric}                 │
│         Returns: Future predictions for next N periods          │
└─────────────────────────────────────────────────────────────────┘
```

---

## Automatic Learning System

### Trigger Points

The auto-learning system is triggered when users add data through these API endpoints:

| Endpoint | Metric | Trigger Location |
|----------|--------|------------------|
| `POST /api/v1/revenue/` | revenue | `app/api/v1/revenue.py:238` |
| `POST /api/v1/expenses/` | expense | `app/api/v1/expenses.py:200` |
| `POST /api/v1/inventory/` | inventory | `app/api/v1/inventory.py:160` |
| `POST /api/v1/sales/` | inventory | `app/api/v1/sales.py:137` |

### Example: Revenue Creation Flow

```python
# app/api/v1/revenue.py
@router.post("/", response_model=RevenueResponse)
async def create_revenue(
    revenue: RevenueCreate,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    # 1. Create revenue entry in database
    db_revenue = revenue_crud.create(db, revenue, current_user.id)
    
    # 2. Record new data for auto-learning
    from ...services.ml_auto_learn import record_new_data, trigger_auto_learn_background
    record_new_data("revenue", count=1)
    
    # 3. Trigger auto-learning in background (non-blocking)
    background_tasks.add_task(trigger_auto_learn_background, "revenue")
    
    return db_revenue
```

### Auto-Learning Decision Logic

```python
# app/services/ml_auto_learn.py

def should_retrain(metric: str) -> bool:
    """
    Decides if models should be retrained based on:
    1. New data count (>= 5 new entries)
    2. Time since last training (>= 24 hours)
    """
    new_count = _new_data_counts.get(metric, 0)
    last_training = _last_training_times.get(metric)
    
    # Need at least 5 new data points
    if new_count < 5:
        return False
    
    # Enforce 24-hour cooldown
    if last_training:
        hours_since = (datetime.now() - last_training).total_seconds() / 3600
        if hours_since < 24:
            return False
    
    return True
```

---

## Model Training Process

### Data Preparation

```python
# 1. Fetch data from database
df = MLForecastingService._prepare_time_series_data(
    db=db,
    metric="revenue",  # or "expense", "inventory"
    start_date=datetime(2023, 1, 1),
    end_date=datetime.now(),
    period="monthly"  # or "daily", "weekly"
)

# 2. Data is aggregated by period
# Result: DataFrame with columns ['date', 'value']
#   date        value
#   2023-01-01  15000
#   2023-02-01  18000
#   2023-03-01  16500
```

### Training Each Model Type

#### 1. Linear Regression (Baseline)
```python
# Simplest model - fits a straight line
# Good for: Basic trends
# Min data: 5 points

model = LinearRegression()
X = np.arange(len(df)).reshape(-1, 1)  # Time index
y = df['value'].values
model.fit(X, y)

# Metrics: MAE, RMSE, R²
```

#### 2. ARIMA (AutoRegressive Integrated Moving Average)
```python
# Statistical time series model
# Good for: Short-term forecasting, stationary data
# Min data: 10 points

model = ARIMA(df['value'], order=(1, 1, 1))
fitted_model = model.fit()

# Metrics: MAE, RMSE, AIC
```

#### 3. SARIMA (Seasonal ARIMA)
```python
# ARIMA with seasonal components
# Good for: Inventory with seasonal patterns
# Min data: 36 points (3 years monthly)

model = SARIMAX(
    df['value'],
    order=(1, 1, 1),
    seasonal_order=(1, 1, 1, 12)  # 12-month seasonality
)
fitted_model = model.fit()

# Metrics: MAE, RMSE, AIC
```

#### 4. Prophet (Facebook's Time Series Model)
```python
# Advanced model with trend + seasonality
# Good for: Long-term forecasts, holidays, multiple seasonalities
# Min data: 36 points

model = Prophet(
    yearly_seasonality=True,
    weekly_seasonality=True,
    seasonality_mode='multiplicative'
)
model.fit(prophet_df)  # Requires 'ds' and 'y' columns

# Metrics: MAE, RMSE
```

#### 5. XGBoost (Gradient Boosting)
```python
# Machine learning ensemble method
# Good for: Non-linear patterns, feature-rich data
# Min data: 12 points

model = xgb.XGBRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=5
)
model.fit(X_train, y_train)

# Metrics: MAE, RMSE, R²
```

#### 6. LSTM (Long Short-Term Memory Neural Network)
```python
# Deep learning for sequences
# Good for: Complex patterns, long-term dependencies
# Min data: 12 points

model = Sequential([
    LSTM(50, activation='relu', input_shape=(n_steps, n_features)),
    Dropout(0.2),
    Dense(1)
])
model.compile(optimizer='adam', loss='mse')
model.fit(X_train, y_train, epochs=50, batch_size=32)

# Metrics: MAE, RMSE
```

---

## Available AI Models

### Model Comparison Table

| Model | Type | Min Data | Best For | Pros | Cons |
|-------|------|----------|----------|------|------|
| **Linear Regression** | Statistical | 5 | Simple trends | Fast, interpretable | Too simple for complex patterns |
| **ARIMA** | Statistical | 10 | Short-term forecasts | Good for stationary data | Requires parameter tuning |
| **SARIMA** | Statistical | 36 | Seasonal inventory | Handles seasonality | Needs lots of data |
| **Prophet** | Statistical | 36 | Long-term, seasonal | Handles holidays, trends | Slow training |
| **XGBoost** | ML Ensemble | 12 | Non-linear patterns | High accuracy | Black box |
| **LSTM** | Deep Learning | 12 | Complex sequences | Learns patterns | Needs GPU, slow |

### Model Selection Strategy

The auto-learning system trains all available models and selects the best one based on:

1. **MAE (Mean Absolute Error)**: Lower is better
2. **RMSE (Root Mean Squared Error)**: Lower is better
3. **Data availability**: Skips models that need more data

```python
# Example: Auto-learning trains 5 models for revenue
results = {
    "linear_regression": {"mae": 1500, "rmse": 2000},
    "arima": {"mae": 1200, "rmse": 1800},
    "prophet": "skipped - insufficient data",
    "xgboost": {"mae": 1100, "rmse": 1700},  # BEST
    "lstm": {"mae": 1250, "rmse": 1850}
}

# XGBoost has lowest MAE → saved as revenue_xgboost.pkl
```

---

## Data Flow

### 1. Training Data Flow

```
Database Tables
├── revenue (approved entries only)
├── expenses (approved entries only)
├── inventory (current stock levels)
└── sales (historical sales)
        │
        ▼
_prepare_time_series_data()
        │
        ▼
Pandas DataFrame
  date        value
  2023-01-01  15000
  2023-02-01  18000
        │
        ▼
Model Training
        │
        ▼
Saved Model Files
├── backend/model/revenue_xgboost.pkl
├── backend/model/expense_arima.pkl
└── backend/store/revenue_xgboost.json (metadata)
```

### 2. Prediction Data Flow

```
API Request
GET /api/v1/budgeting/forecast/revenue?periods=6
        │
        ▼
Load Trained Model
revenue_xgboost.pkl
        │
        ▼
Generate Predictions
[18500, 19000, 19500, 20000, 20500, 21000]
        │
        ▼
API Response
{
  "metric": "revenue",
  "model_type": "xgboost",
  "predictions": [...],
  "dates": [...]
}
```

---

## API Integration

### Manual Training Endpoints

```python
# Train all models for a metric
POST /api/v1/budgeting/train/{metric}
# metric: "revenue", "expense", "inventory"

# Train specific model type
POST /api/v1/budgeting/train/{metric}/{model_type}
# model_type: "arima", "prophet", "xgboost", "lstm", etc.

# Trigger auto-learning manually
POST /api/v1/budgeting/auto-learn/{metric}?force=true
```

### Prediction Endpoints

```python
# Get forecast for next N periods
GET /api/v1/budgeting/forecast/{metric}?periods=6&model_type=xgboost

# Get list of trained models
GET /api/v1/budgeting/models?metric=revenue

# Get auto-learning status
GET /api/v1/budgeting/auto-learn/status
```

---

## Configuration

### Environment Variables

```bash
# Scheduler Configuration
ML_SCHEDULER_ENABLED=true
ML_SCHEDULER_DAY=mon        # Day of week for retraining
ML_SCHEDULER_HOUR=2         # Hour (0-23)
ML_SCHEDULER_MINUTE=0       # Minute (0-59)

# Auto-Learning Thresholds
ML_AUTO_LEARN_MIN_DATA=5    # Min new entries before retraining
ML_AUTO_LEARN_COOLDOWN=24   # Hours between retraining
```

### Model Storage Locations

```
backend/
├── model/                  # Trained model files
│   ├── revenue_xgboost.pkl
│   ├── expense_arima.pkl
│   └── inventory_sarima.pkl
├── store/                  # Model metadata
│   ├── revenue_xgboost.json
│   ├── expense_arima.json
│   └── auto_learn_state.json
```

---

## Summary

The AI/ML system in the backend is a **fully automated, intelligent forecasting engine** that:

1. ✅ **Automatically learns** from new data without manual intervention
2. ✅ **Trains 6 different models** and picks the best performer
3. ✅ **Runs in the background** without blocking user requests
4. ✅ **Provides accurate forecasts** for revenue, expenses, and inventory
5. ✅ **Self-improves** over time as more data becomes available

This creates a **hands-off AI system** where users simply enter their financial data, and the backend automatically trains, evaluates, and deploys the best forecasting models.